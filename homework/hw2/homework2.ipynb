{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URzxYKCYrwW5"
      },
      "source": [
        "# Homework2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 3D Reconstuction \n",
        "Describe the NeRF (Neural Radiance Fields) algorithm by answering the following three points clearly and concisely (3 points):\n",
        "- What are the inputs and outputs of NeRF?\n",
        "- What is the training loss? How to compute the gradient?\n",
        "- What training data does NeRF require?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Instantaneous Change of Variables\n",
        "Derive the Instantaneous Change of Variables formula:\n",
        "$$ \\frac{d}{dt} \\log p(\\mathbf{z}(t)) = -\\operatorname{tr}\\left( \\frac{d f}{d \\mathbf{z}(t)} \\right),$$\n",
        "where the dynamics are given by\n",
        "$$\\frac{d\\mathbf{z}(t)}{dt} = f(\\mathbf{z}(t), t),$$\n",
        "\n",
        "and the function  f  is assumed to be uniformly Lipschitz continuous in  $\\mathbf{z}$  and continuous in  t . Provide at least **two ways** to prove it. (4 points)\n",
        "\n",
        "Hints:\n",
        "- Hint 1: Consider the time limit of the discrete change-of-variables formula.\n",
        "- Hint 2: You may utilize the Fokker-Planck equation in the deterministic case.\n",
        "- Hint 3: You may introduce a smooth test function to rigorously justify the derivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Large Language Models \n",
        "\n",
        "LLMs model a joint distribution over a sequence $ x_1, \\dots, x_T $ by factorizing it into conditional distributions\n",
        "$$ p(x_1,\\dots,x_T)=\\prod_{t=1}^T p(x_t \\mid x_{<t}),$$\n",
        "and learning these conditionals through next-token prediction.\n",
        "\n",
        "Answer the following:\n",
        "- How is next-token prediction implemented in practice using a Transformer decoder? (1 pts)\n",
        "\n",
        "- Identify the training setup:including the input,output and traning objective. (2 pts)\n",
        "\n",
        "- What is the difference between sampling during training and inference? Why? (2 pts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Coding: VAE on MNIST\n",
        "A Python notebook with the code to be completed is provided. Please complete it using the following intructions. This problem is adapted from the pset1 of [Course 6.S978 Deep Generative Models](https://mit-6s978.github.io/schedule.html) given by Professor Kaiming He at MIT.\n",
        "\n",
        "VAEs are trained by maximizing the Evidence Lower Bound (ELBO) on the marginal log-likelihood:\n",
        "$$\\log p(x) \\geq \\mathbb{E}_{q(z|x)}[\\log\\frac{p(x, z)}{q(z|x)}] = \\mathrm{ELBO},$$\n",
        "\n",
        "where $x$ is the data (binary images for MNIST) and $z$ is the latent code.\n",
        "\n",
        "(a) Give a detailed mathematical proof of the ELBO starting from the marginal\n",
        "log-likelihood log p(x).(2 Points)\n",
        "\n",
        "(b) Complete the implementation of the  ``self.encoder`` and ``self.decoder`` in the\n",
        "``VAE()`` model. (2 Points)\n",
        "\n",
        "(c) Implement the reparameterization trick in the ``reparameterize()`` function. In this assignment, we only sample one latent code $z_{i}$ for each $x_i$. (1 Points)\n",
        "\n",
        "(d) In practice, the above expectation in ELBO is estimated using Monte Carlo sampling, yielding the generic Stoachastic Gradient Variational Bayes (SGVB) estimator,\n",
        "$$\\mathrm{ELBO} \\approx \\sum_{i} [\\log p(x_i|z_{i}) + \\log p(z_{i}) - \\log q(z_{i}|x_i)], $$\n",
        "where $z_{i}$ is sampled from $ q(z|x_i) = \\mathcal{N}(z;\\mu_i, \\sigma^2_i \\mathbf{I})$. \n",
        "\n",
        "Finalize the SGVB estimator by completing the ``log_normal_pdf()``  function, which computes the log probability for a normal distribution given its mean and variance.(1 Points)\n",
        "\n",
        "(e) In many cases, Monte Carlo sampling is not necessary to estimate all the terms of ELBO, as some terms can be integrated analytically. In particular, when both $q(z|x)=\\mathcal{N}(z;\\mu(x),\\mathrm{diag}(\\sigma^2(x)))$ and $p(z)=\\mathcal{N}(z;0,I)$ are\n",
        "Gaussian distributions, the ELBO can be decomposed into an analytical KL divergence plus\n",
        "the expected reconstruction error:\n",
        "$$\\mathrm{ELBO} â‰ˆ -D_{KL}(q(z|x) || p(z)) + \\sum_{i} \\log p(x_i|z_{i}) = \\\\\\frac{1}{2}\\sum_{d}(1+\\log((\\sigma_d)^2) - (\\mu_d)^2 - (\\sigma_d)^2) + \\sum_{i} \\log p(x_i|z_{i})$$\n",
        "where d is the dimension of the latent space, and i is the indices of the data.\n",
        "\n",
        "Run the verfirication code to check if the analytical KL divergence matches the Monte Carlo estimate. (2 Points)\n",
        "\n",
        "(f) Using the above two losses, train two VAE models on the MNIST dataset (manual\n",
        "tuning of parameters such as epochs, hidden dims, lr, coeff may be necessary).\n",
        "Use the provided evaluation code to visualize the reconstruction results and the\n",
        "generated images (in 2D grid) for both models. (3 Points)\n",
        "\n",
        "(g) Latent Interpolation:\n",
        "Encode two MNIST test images with different digit labels to obtain latent codes z_1 and z_2. Linearly interpolate between them using z(\\alpha) = (1-\\alpha)z_1 + \\alpha z_2 for \\alpha\\in\\{0,0.1,\\dots,1\\}, decode each interpolated code with your trained VAE decoder, and display the generated images in order. Briefly describe how the generated digits gradually transform from one class to the other along the interpolation. (2 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Code to Be Completed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saoGocoSmPjr"
      },
      "source": [
        "#### Import Libraries and Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsFz9_IOmQSO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UDt9qORli83"
      },
      "source": [
        "### MNIST Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVRCzm6jko7-"
      },
      "outputs": [],
      "source": [
        "tensor_transform = transforms.ToTensor()\n",
        "\n",
        "batch_size = 256\n",
        "MNIST_dataset = datasets.MNIST(root = \"./data\",\n",
        "\t\t\t\t\t\t\t\t\ttrain = True,\n",
        "\t\t\t\t\t\t\t\t\tdownload = True,\n",
        "\t\t\t\t\t\t\t\t\ttransform = tensor_transform)\n",
        "\n",
        "MNIST_loader = torch.utils.data.DataLoader(dataset = MNIST_dataset,\n",
        "\t\t\t\t\t\t\t   batch_size = batch_size,\n",
        "\t\t\t\t\t\t\t\t shuffle = True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlqPb9uAZWVX"
      },
      "source": [
        "### Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUV53Q08ZVTB"
      },
      "outputs": [],
      "source": [
        "from math import e\n",
        "mse = torch.nn.MSELoss()\n",
        "\n",
        "def loss_func(model, x, reg_func=None, coeff=1e-3):\n",
        "    output = model(x)\n",
        "    err = mse(output['imgs'], x)\n",
        "    logpx_z = -1.0 * torch.sum(err)\n",
        "\n",
        "    if reg_func is not None:\n",
        "      reg = reg_func(output)\n",
        "    else:\n",
        "      reg = 0.0\n",
        "\n",
        "    return -1.0 * torch.mean(logpx_z + coeff * reg)\n",
        "\n",
        "def train(dataloader, model, loss_func, optimizer, epochs):\n",
        "    losses = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs), desc='Epochs'):\n",
        "        running_loss = 0.0\n",
        "        batch_progress = tqdm(dataloader, desc='Batches', leave=False)\n",
        "\n",
        "        for iter, (images, labels) in enumerate(batch_progress):\n",
        "            batch_size = images.shape[0]\n",
        "            images = images.reshape(batch_size, -1).to(device)\n",
        "            loss = loss_func(model, images)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            avg_loss = running_loss / len(MNIST_dataset) * batch_size\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        tqdm.write(f'----\\nEpoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}\\n')\n",
        "\n",
        "    return losses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nlH6ETubTuj"
      },
      "source": [
        "### Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beLPLaqgbYLF"
      },
      "outputs": [],
      "source": [
        "def plot_latent_images(model, n, digit_size=28):\n",
        "    grid_x = np.linspace(-2, 2, n)\n",
        "    grid_y = np.linspace(-2, 2, n)\n",
        "\n",
        "    image_width = digit_size * n\n",
        "    image_height = digit_size * n\n",
        "    image = np.zeros((image_height, image_width))\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z = torch.tensor([[xi, yi]], dtype=torch.float32).to(device)\n",
        "            with torch.no_grad():\n",
        "                x_decoded = model.decode(z)\n",
        "            digit = x_decoded.view(digit_size, digit_size).cpu().numpy()\n",
        "            image[i * digit_size: (i + 1) * digit_size,\n",
        "                  j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image, cmap='Greys_r')\n",
        "    plt.axis('Off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def eval(model):\n",
        "    original_imgs = torch.cat([MNIST_dataset[i][0] for i in range(5)])\n",
        "    with torch.no_grad():\n",
        "      res = model(original_imgs.reshape(5, -1).to(device))\n",
        "      reconstructed_imgs = res['imgs']\n",
        "      reconstructed_imgs = reconstructed_imgs.cpu().reshape(*original_imgs.shape)\n",
        "\n",
        "    fig, axes = plt.subplots(5, 2, figsize=(10, 25))\n",
        "\n",
        "    for i in range(5):\n",
        "        original_image = original_imgs[i].reshape(28, 28)\n",
        "        axes[i, 0].imshow(original_image, cmap='gray')\n",
        "        axes[i, 0].set_title(f'Original Image {i+1}')\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        reconstructed_image = reconstructed_imgs[i].reshape(28, 28)\n",
        "        axes[i, 1].imshow(reconstructed_image, cmap='gray')\n",
        "        axes[i, 1].set_title(f'Reconstructed Image {i+1}')\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znrLQMSYlZb9"
      },
      "source": [
        "\n",
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeZBbuuolcoI"
      },
      "outputs": [],
      "source": [
        "class VAE(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dims, decode_dim=-1, use_sigmoid=True):\n",
        "      '''\n",
        "      input_dim: The dimensionality of the input data.\n",
        "      hidden_dims: A list of hidden dimensions for the layers of the encoder and decoder.\n",
        "      decode_dim: (Optional) Specifies the dimensions to decode, if different from input_dim.\n",
        "      '''\n",
        "      super().__init__()\n",
        "\n",
        "      self.z_size = hidden_dims[-1] // 2\n",
        "\n",
        "      self.encoder = torch.nn.Sequential()\n",
        "      self.decoder = torch.nn.Sequential()\n",
        "      ##################\n",
        "      ### Problem 2 (a): finish the implementation for encoder and decoder\n",
        "      ##################\n",
        "\n",
        "  def encode(self, x):\n",
        "      mean, logvar = torch.split(self.encoder(x), split_size_or_sections=[self.z_size, self.z_size], dim=-1)\n",
        "      return mean, logvar\n",
        "\n",
        "  def reparameterize(self, mean, logvar, n_samples_per_z=1):\n",
        "      ##################\n",
        "      ### Problem 2(b): finish the implementation for reparameterization\n",
        "      ##################\n",
        "      pass\n",
        "\n",
        "  def decode(self, z):\n",
        "      probs = self.decoder(z)\n",
        "      return probs\n",
        "\n",
        "  def forward(self, x, n_samples_per_z=1):\n",
        "      mean, logvar = self.encode(x)\n",
        "\n",
        "      batch_size, latent_dim = mean.shape\n",
        "      if n_samples_per_z > 1:\n",
        "        mean = mean.unsqueeze(1).expand(batch_size, n_samples_per_z, latent_dim)\n",
        "        logvar = logvar.unsqueeze(1).expand(batch_size, n_samples_per_z, latent_dim)\n",
        "\n",
        "        mean = mean.contiguous().view(batch_size * n_samples_per_z, latent_dim)\n",
        "        logvar = logvar.contiguous().view(batch_size * n_samples_per_z, latent_dim)\n",
        "\n",
        "      z = self.reparameterize(mean, logvar, n_samples_per_z)\n",
        "      x_probs = self.decode(z)\n",
        "\n",
        "      x_probs = x_probs.reshape(batch_size, n_samples_per_z, -1)\n",
        "      x_probs = torch.mean(x_probs, dim=[1])\n",
        "\n",
        "      return {\n",
        "          \"imgs\": x_probs,\n",
        "          \"z\": z,\n",
        "          \"mean\": mean,\n",
        "          \"logvar\": logvar\n",
        "      }\n",
        "\n",
        "### Test\n",
        "hidden_dims = [128, 64, 36, 18, 18]\n",
        "input_dim = 256\n",
        "test_tensor = torch.randn([1, input_dim]).to(device)\n",
        "\n",
        "vae_test = VAE(input_dim, hidden_dims).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  test_out = vae_test(test_tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1uNMVp4bHVM"
      },
      "source": [
        "### Loss Functions\n",
        "#### Loss 1: Stoachastic Gradient Variational Bayes (SGVB) Estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2QMPmCSbO94"
      },
      "outputs": [],
      "source": [
        "##### Loss 1: SGVB #####\n",
        "log2pi = torch.log(2.0 * torch.tensor(np.pi)).to(device)\n",
        "torch_zero = torch.tensor(0.0).to(device)\n",
        "\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "    ##################\n",
        "    ### Problem 2(c): finish the implementation for the log-probability for normal distribution with mean and var\n",
        "    ##################\n",
        "    pass\n",
        "\n",
        "def loss_SGVB(output):\n",
        "    logpz = log_normal_pdf(output['z'], torch_zero, torch_zero)\n",
        "    logqz_x = log_normal_pdf(output['z'], output['mean'], output['logvar'])\n",
        "    return logpz -logqz_x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvtkFSAjt2o7"
      },
      "source": [
        "### Loss 2: KL Divergence w/o Estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8_BR39pt20a"
      },
      "outputs": [],
      "source": [
        "##### Loss 2: KL w/o Estimation #####\n",
        "def loss_KL_wo_E(output):\n",
        "    var = torch.exp(output['logvar'])\n",
        "    logvar = output['logvar']\n",
        "    mean = output['mean']\n",
        "\n",
        "    return -0.5 * torch.sum(torch.pow(mean, 2)\n",
        "                            + var - 1.0 - logvar,\n",
        "                            dim=[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogJfK717tEAr"
      },
      "source": [
        "### Verifying loss 1 == loss 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8nIZuXa5Tk_"
      },
      "outputs": [],
      "source": [
        "##################\n",
        "### Problem 2(d): Check if the analytical KL divergence matches the Monte Carlo estimate.\n",
        "hidden_dims = [128, 32, 16, 4]\n",
        "image_shape = MNIST_dataset[0][0].shape\n",
        "input_dim = torch.prod(torch.tensor(image_shape)).item()\n",
        "vae_test = VAE(input_dim, hidden_dims).to(device)\n",
        "\n",
        "all_l_sgvb, all_KL_wo_E = [], []\n",
        "all_n_samples_per_z = list(range(1, 4000, 100))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for n_samples_per_z in all_n_samples_per_z:\n",
        "        for _, (imgs, _) in enumerate(MNIST_loader):\n",
        "            batch_size = imgs.shape[0]\n",
        "            imgs = imgs.reshape(batch_size, -1).to(device)\n",
        "\n",
        "            output = vae_test(imgs, n_samples_per_z=n_samples_per_z)\n",
        "\n",
        "            l_sgvb = torch.mean(loss_SGVB(output))\n",
        "            l_KL_wo_E = torch.mean(loss_KL_wo_E(output))\n",
        "\n",
        "            all_l_sgvb.append(l_sgvb.item())\n",
        "            all_KL_wo_E.append(l_KL_wo_E.item())\n",
        "            break\n",
        "\n",
        "# Plot the two curves\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.plot(all_n_samples_per_z, all_l_sgvb, label='SGVB Loss')\n",
        "plt.plot(all_n_samples_per_z, all_KL_wo_E, label='KL Divergence (w/o E)')\n",
        "\n",
        "plt.xlabel('Number of Samples per z')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "##################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nircBTxhitxo"
      },
      "source": [
        "### Training with SGVB loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sub8yMlhiuLo"
      },
      "outputs": [],
      "source": [
        "##################\n",
        "### Problem 2(e): Train VAE with SGVB loss\n",
        "epochs = 20\n",
        "\n",
        "hidden_dims = [128, 32, 16, 4]\n",
        "assert hidden_dims[-1] == 4, \"always use 4 as the latent dimension for generating a 2D image grid during evaluation\"\n",
        "\n",
        "image_shape = MNIST_dataset[0][0].shape\n",
        "input_dim = torch.prod(torch.tensor(image_shape)).item()\n",
        "print(\"input_dim: \", input_dim)\n",
        "\n",
        "vae_sgvb = VAE(input_dim, hidden_dims).to(device)\n",
        "print(vae_sgvb)\n",
        "\n",
        "coeff = 1e-3\n",
        "\n",
        "optimizer_vae_sgvb = torch.optim.Adam(vae_sgvb.parameters(),\n",
        "                                lr = 1e-4,\n",
        "                                weight_decay = 1e-8)\n",
        "\n",
        "log_vae_sgvb = train(MNIST_loader, vae_sgvb, lambda model, x: loss_func(model, x, reg_func=loss_SGVB, coeff=1e-3), optimizer_vae_sgvb, epochs)\n",
        "\n",
        "### Evalutaion\n",
        "eval(vae_ELBO)\n",
        "plot_latent_images(vae_ELBO, n=8)\n",
        "##################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Trainimg with analytical KL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvaKlqDjIJKv"
      },
      "outputs": [],
      "source": [
        "##################\n",
        "### Problem 2(e): Train VAE with analytical KL\n",
        "epochs = 20\n",
        "\n",
        "hidden_dims = [128, 32, 16, 4]\n",
        "assert hidden_dims[-1] == 4, \"always use 4 as the latent dimension for generating a 2D image grid during evaluation\"\n",
        "\n",
        "image_shape = MNIST_dataset[0][0].shape\n",
        "input_dim = torch.prod(torch.tensor(image_shape)).item()\n",
        "print(\"input_dim: \", input_dim)\n",
        "\n",
        "vae_kl_wo_e = VAE(input_dim, hidden_dims).to(device)\n",
        "print(vae_kl_wo_e)\n",
        "\n",
        "optimizer_vae_kl_wo_e = torch.optim.Adam(vae_kl_wo_e.parameters(),\n",
        "                                lr = 1e-4,\n",
        "                                weight_decay = 1e-8)\n",
        "\n",
        "log_vae_kl_wo_e = train(MNIST_loader, vae_kl_wo_e, lambda model, x: loss_func(model, x, reg_func=loss_KL_wo_E, coeff=1e-3), optimizer_vae_kl_wo_e, epochs)\n",
        "\n",
        "\n",
        "### Evaluation\n",
        "eval(vae_kl_wo_e)\n",
        "plot_latent_images(vae_kl_wo_e, n=8)\n",
        "##################\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
