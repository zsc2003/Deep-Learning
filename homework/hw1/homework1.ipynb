{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.[2pts]Consider a sequence of values $\\{x_1, x_2,\\dots, x_n\\}$ of some variable x, and suppose\n",
    "we compute an exponentially weighted moving average using the formula\n",
    "$\\mu_n =\\beta \\mu_{n-1}+(1-\\beta)x_n $\n",
    "where $0<\\beta<1$. By making use of the following result for the sum of a finite\n",
    "geometric series\n",
    "$$\\sum_k=1^n \\beta_{k-1} = \\frac{1-\\beta^n}{1-\\beta},$$\n",
    "show that if the sequence of averages is initialized using µ0 = 0, then the estimators\n",
    "are biased and that the bias can be corrected using\n",
    "$$\\hat \\mu_n=\\frac{\\mu_n}{1-\\beta^n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [3pts]Prove the shift invariant property of convolution: \n",
    "$$\\mathcal{G}(f(\\cdot-a))(x)=\\mathcal{G}(f(\\cdot))(x-a),$$\n",
    "where $\\mathcal{G}$ is the convolutional operator $\\mathcal{G}(f(\\cdot))=\\int_{-\\infty}^{+\\infty} f(\\tau)h(x-\\tau)d\\tau$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Neural Network Architectures \n",
    "(1)[3pts] Derive the number of trainable parameters in a single convolutional layer with input size $H \\times W \\times C_{\\mathrm{in}}$, kernel size $k \\times k$, and $C_{\\mathrm{out}}$ output channels (assume bias), and compare it with a fully connected (dense) layer of the same input and output size. \n",
    "(2)[2pts]Explain why positional information is necessary in Transformers and describe one method to inject positional information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.[15pts]Training a Convolutional Neural Network (CNN) on EuroSAT for Image Classification\n",
    "\n",
    "In this assignment, you will train a deep learning model from scratch for EuroSAT dataset classification. EuroSAT is a dataset of 27,000 RGB satellite images (64×64 pixels) across 10 land cover classes, derived from Sentinel-2 satellite data for remote sensing classification tasks.\n",
    "\n",
    "You are required to complete the following code by **filling in your own architecture and training function.** In the sections that specify **“To be implemented by students”**, you should replace pass with your own implementation.\n",
    "\n",
    "After completing the implementation, answer the following questions and submit a report in Markdown/PDF format.\n",
    "- Estimate the number of parameters and the feature map sizes at each layer.\n",
    "- Report training accuracy and loss over epoches and the testing accuracy on test data.\n",
    "- Compare training and test error with and without Batch Normalization and Dropout layers.\n",
    "- Please also submit the Jupyter Notebook (.ipynb) with your complete, executable code.(You can just edit on this notebook file.)\n",
    "\n",
    "\n",
    "### Notes:\n",
    "- **Google Colab or AutoDL is recommended for training if you don’t have a local GPU.**\n",
    "- **Submission Deadline: November 2, 11:59 PM**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Setup: Load Dataset & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import time\n",
    "\n",
    "# Ensure GPU usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize images\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standardization\n",
    "])\n",
    "\n",
    "# Load EuroSAT dataset\n",
    "dataset = datasets.EuroSAT(root=\"./data\", transform=transform, download=True)\n",
    "\n",
    "# Split dataset into 80% training and 20% testing\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the Neural Network (**To be implemented by students**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        # TODO: Define your CNN model architecture\n",
    "        # - Experiment with different layers, number of filters, kernel sizes\n",
    "        # - Try using BatchNorm, Dropout, and deeper architectures\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define the Training Function (**To be implemented by students**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=10):\n",
    "    \"\"\"\n",
    "    Train the model and measure performance.\n",
    "    - Record training time per epoch\n",
    "    - Report training loss and accuracy\n",
    "    - Measure training time per model architecture\n",
    "    \"\"\"\n",
    "    # TODO: Implement the training loop\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model and move to device\n",
    "model = MyCNN().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, device, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = test_loss / total\n",
    "    test_acc = correct / total * 100\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "# Evaluate the trained model\n",
    "evaluate_model(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
